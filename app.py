"""
AV Monitor - æ–°ç€ãƒã‚§ãƒƒã‚¯ Web ã‚¢ãƒ—ãƒª
=====================================
ç™»éŒ²å¥³å„ªã®æ–°ä½œï¼ˆé€šè²©/äºˆç´„æƒ…å ±ï¼‰ã‚’DMM APIã§æ¤œç´¢ã—ã€
ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã«æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚«ãƒ¼ãƒ‰ã§ä¸€è¦§è¡¨ç¤ºã™ã‚‹ã€‚
ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéè¡¨ç¤ºï¼‰ã§å¥³å„ªã®ä¸€æ‹¬æ¤œç´¢ãƒ»è¿½åŠ ã€
ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ã§ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†ãŒå¯èƒ½ã€‚
"""

import re
import uuid
import streamlit as st
import requests
import gspread
import pandas as pd
import urllib.parse
import feedparser
import time
from streamlit_sortables import sort_items
from oauth2client.service_account import ServiceAccountCredentials
from filters import filter_items

# ---------------------------------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š & ã‚«ã‚¹ã‚¿ãƒ CSS (ãƒ–ãƒ©ãƒƒã‚¯ Ã— ãƒ”ãƒ³ã‚¯ ãƒ†ãƒ¼ãƒ)
# ---------------------------------------------------------------------------
st.set_page_config(
    page_title="AV Monitor",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="collapsed",
)

st.markdown(
    """
    <style>
    /* ===== ã‚°ãƒ­ãƒ¼ãƒãƒ« ===== */
    :root {
        --bg:       #0a0a0a;
        --bg-card:  #141414;
        --bg-hover: #1e1e1e;
        --pink:     #ff4d8d;
        --pink-dim: #cc3d71;
        --txt:      #f0f0f0;
        --txt-sub:  #bbb;
    }
    html, body, [data-testid="stAppViewContainer"],
    [data-testid="stSidebar"], [data-testid="stHeader"],
    .main .block-container {
        background-color: var(--bg) !important;
        color: var(--txt) !important;
    }
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #0d0d0d 0%, #111 100%) !important;
        border-right: 1px solid #222 !important;
    }
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®å…¨ãƒ†ã‚­ã‚¹ãƒˆ */
    [data-testid="stSidebar"] * {
        color: var(--txt) !important;
    }
    [data-testid="stHeader"] { background: transparent !important; }
    /* Streamlit ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼ (Share/Star) ã‚’éè¡¨ç¤º (ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒœã‚¿ãƒ³ã¯æ®‹ã™) */
    [data-testid="stDecoration"],
    .stDeployButton,
    [data-testid="stToolbar"] [data-testid="stToolbarActions"] {
        display: none !important;
    }
    .block-container { max-width: 100%; padding: 1rem 2rem; }

    /* ===== ãƒœã‚¿ãƒ³å…¨èˆ¬ ===== */
    .stButton > button,
    .stFormSubmitButton > button,
    button[kind="secondary"],
    button[data-testid="stBaseButton-secondary"] {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
        border: 1px solid #333 !important;
        border-radius: 8px !important;
        transition: all 0.2s ease;
    }
    .stButton > button:hover,
    .stFormSubmitButton > button:hover {
        border-color: var(--pink) !important;
        color: var(--pink) !important;
        box-shadow: 0 0 8px rgba(255,77,141,0.25);
    }
    /* ãƒ—ãƒ©ã‚¤ãƒãƒªãƒœã‚¿ãƒ³ */
    .stButton > button[kind="primary"],
    .stFormSubmitButton > button[kind="primary"],
    button[data-testid="stBaseButton-primary"],
    [data-testid="stFormSubmitButton"] > button {
        background: var(--pink) !important;
        border: none !important;
        color: #fff !important;
    }
    .stButton > button[kind="primary"]:hover,
    [data-testid="stFormSubmitButton"] > button:hover {
        background: var(--pink-dim) !important;
        box-shadow: 0 0 12px rgba(255,77,141,0.4);
    }

    /* ===== ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ç¯„å›²æ‹¡å¤§ ===== */
    .stButton > button,
    .stFormSubmitButton > button {
        min-height: 38px !important;
        padding: 6px 16px !important;
        cursor: pointer !important;
    }

    /* ===== Expander (ç™½èƒŒæ™¯ã‚’å®Œå…¨æ’é™¤) ===== */
    [data-testid="stExpander"] {
        background: var(--bg-card) !important;
        border: 1px solid #222 !important;
        border-radius: 10px !important;
        margin-bottom: 8px;
    }
    details {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
    }
    details > summary {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
        font-weight: 600;
    }
    details > summary *,
    details > summary span,
    details > summary p {
        color: var(--txt) !important;
    }
    [data-testid="stExpander"] summary,
    [data-testid="stExpander"] summary span,
    [data-testid="stExpander"] summary p,
    [data-testid="stExpander"] [data-testid="stMarkdownContainer"] p {
        color: var(--txt) !important;
        font-weight: 600;
    }
    [data-testid="stExpander"] > div,
    [data-testid="stExpander"] > div > div {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
    }
    [data-testid="stExpander"] summary:hover,
    [data-testid="stExpander"] summary:hover span,
    details > summary:hover,
    details > summary:hover * {
        color: var(--pink) !important;
    }

    /* ===== textarea ãƒ’ãƒ³ãƒˆ (Ctrl+Enter) ã‚’éš ã™ ===== */
    [data-testid="stTextArea"] .stTextArea-instructions,
    [data-testid="stTextArea"] div[data-testid="InputInstructions"],
    div[data-testid="InputInstructions"] {
        display: none !important;
    }

    /* ===== Popover ===== */
    [data-testid="stPopover"] > div,
    [data-testid="stPopoverBody"],
    [data-testid="stPopoverBody"] > div {
        background: var(--bg-card) !important;
        border: 1px solid #333 !important;
        color: var(--txt) !important;
    }
    [data-testid="stPopoverBody"] p,
    [data-testid="stPopoverBody"] span,
    [data-testid="stPopoverBody"] label,
    [data-testid="stPopoverBody"] .stMarkdown {
        color: var(--txt) !important;
    }

    /* ===== Form å†…éƒ¨ ===== */
    [data-testid="stForm"] {
        background: var(--bg-card) !important;
        border: 1px solid #222 !important;
        border-radius: 10px !important;
        padding: 12px !important;
    }
    [data-testid="stForm"] label,
    [data-testid="stForm"] span,
    [data-testid="stForm"] p {
        color: var(--txt) !important;
    }

    /* ===== Dialog / Toast ===== */
    [data-testid="stDialog"] > div,
    [data-testid="stToast"],
    div[role="dialog"],
    div[data-modal-container="true"] {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
    }

    /* ===== Checkbox / Radio ===== */
    .stCheckbox label span,
    .stRadio label span {
        color: var(--txt) !important;
    }

    /* ===== Baseweb (å†…éƒ¨ UI ãƒ©ã‚¤ãƒ–ãƒ©ãƒª) ===== */
    div[data-baseweb] { color: var(--txt) !important; }
    div[data-baseweb="popover"] { background: var(--bg-card) !important; }
    div[data-baseweb="select"] > div {
        background: #1a1a1a !important;
        border-color: #333 !important;
        color: var(--txt) !important;
    }
    /* selectbox / listbox ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ (äºˆæ¸¬æ¬„) */
    ul[data-baseweb="menu"],
    div[data-baseweb="popover"] > div,
    [data-baseweb="list"] {
        background: var(--bg-card) !important;
    }
    ul[data-baseweb="menu"] li,
    [data-baseweb="list"] li,
    [role="listbox"] li,
    [role="option"] {
        background: var(--bg-card) !important;
        color: var(--txt) !important;
    }

    /* ===== å…¥åŠ› ===== */
    input, textarea, [data-testid="stTextInput"] input,
    [data-testid="stTextArea"] textarea {
        background: #1a1a1a !important;
        color: var(--txt) !important;
        border: 1px solid #333 !important;
        border-radius: 8px !important;
    }
    input:focus, textarea:focus { border-color: var(--pink) !important; }

    /* selectbox */
    [data-testid="stSelectbox"] > div > div {
        background: #1a1a1a !important;
        border: 1px solid #333 !important;
    }

    /* ===== ãƒ†ã‚­ã‚¹ãƒˆå¯èª­æ€§ (åŒ…æ‹¬çš„) ===== */
    p, li, label, span, .stMarkdown, .stCaption,
    [data-testid="stText"], [data-testid="stCaptionContainer"],
    [data-testid="stMarkdownContainer"] {
        color: var(--txt) !important;
    }
    .stCaption, [data-testid="stCaptionContainer"] p {
        color: var(--txt-sub) !important;
    }
    h1, h2, h3, h4, h5, h6 { color: var(--txt) !important; }
    code { color: var(--pink) !important; background: #1a1a1a !important; }
    .stAlert p { color: var(--txt) !important; }

    /* --- å¥³å„ªãƒ˜ãƒƒãƒ€ãƒ¼ --- */
    .actress-hdr {
        display: flex;
        align-items: center;
        gap: 10px;
        margin: 6px 0 8px;
    }
    .actress-hdr img {
        width: 44px; height: 44px;
        border-radius: 50%;
        object-fit: cover;
        border: 2px solid var(--pink);
        flex-shrink: 0;
    }
    .actress-hdr .name {
        font-size: 1.1rem;
        font-weight: 700;
        color: var(--txt);
        white-space: nowrap;
    }
    .actress-hdr a.missav {
        font-size: 0.75rem;
        color: var(--pink);
        text-decoration: none;
        white-space: nowrap;
    }
    .actress-hdr a.missav:hover { text-decoration: underline; }

    /* --- æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« --- */
    .hscroll {
        display: flex;
        overflow-x: auto;
        overflow-y: visible;
        gap: 12px;
        padding: 8px 4px 20px;
        -webkit-overflow-scrolling: touch;
        scroll-snap-type: x mandatory;
    }
    .hscroll::-webkit-scrollbar { height: 4px; }
    .hscroll::-webkit-scrollbar-track { background: transparent; }
    .hscroll::-webkit-scrollbar-thumb {
        background: var(--pink-dim); border-radius: 4px;
    }
    .hscroll::-webkit-scrollbar-thumb:hover { background: var(--pink); }

    /* --- ä½œå“ã‚«ãƒ¼ãƒ‰ --- */
    .icard {
        flex: 0 0 150px;
        scroll-snap-align: start;
        text-decoration: none;
        color: inherit;
        transition: transform 0.15s ease, box-shadow 0.15s ease;
    }
    .icard:hover {
        transform: translateY(-4px);
        filter: brightness(1.1);
    }
    .icard img {
        width: 150px;
        height: 210px;
        object-fit: cover;
        border-radius: 8px;
        display: block;
        border: 1px solid #222;
    }
    .icard .ttl {
        font-size: 0.72rem;
        font-weight: 600;
        color: #f0f0f0;
        margin-top: 4px;
        display: -webkit-box;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
        overflow: hidden;
        white-space: normal;
        line-height: 1.3;
    }
    .icard .dt {
        font-size: 0.65rem;
        color: var(--pink);
        margin-top: 2px;
    }

    /* åŒºåˆ‡ã‚Šç·š */
    hr { border-color: #222 !important; }

    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼æ¤œç´¢çµæœã‚«ãƒ¼ãƒ‰ */
    .sr-card {
        background: var(--bg-hover);
        border: 1px solid #333;
        border-radius: 8px;
        padding: 8px 10px;
        margin-bottom: 6px;
        display: flex;
        align-items: center;
        gap: 8px;
    }
    .sr-card img {
        width: 40px; height: 40px;
        border-radius: 50%;
        object-fit: cover;
        border: 1px solid var(--pink);
    }
    .sr-card .sr-name {
        font-weight: 600;
        color: var(--txt);
        font-size: 0.85rem;
    }
    .sr-card .sr-id {
        font-size: 0.7rem;
        color: var(--pink);
    }

    @media (max-width: 768px) {
        .block-container { padding: 0.5rem; }
        .icard { flex: 0 0 130px; }
        .icard img { width: 130px; height: 182px; }
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ---------------------------------------------------------------------------
# å®šæ•°ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ­ã‚¸ãƒƒã‚¯ã¯ filters.py ã«çµ±ä¸€æ¸ˆã¿ï¼‰
# ---------------------------------------------------------------------------
MAX_ITEMS_PER_ACTRESS = 5

# ---------------------------------------------------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
# ---------------------------------------------------------------------------
for key, default in {
    "search_results": {},       # name -> [actress dicts]
    "nh_search_results": {},    # name -> {articles, face_img}
    "search_error": "",
    "add_success": "",
    "edit_mode": False,
    "pending_names": "",        # æ¤œç´¢å¾…ã¡åå‰ãƒ†ã‚­ã‚¹ãƒˆ
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# ---------------------------------------------------------------------------
# Google Sheets æ¥ç¶š
# ---------------------------------------------------------------------------
SCOPES = [
    "https://spreadsheets.google.com/feeds",
    "https://www.googleapis.com/auth/drive",
]
SERVICE_ACCOUNT_FILE = "service_account.json"


@st.cache_resource(ttl=300)
def _get_gspread_client():
    if "gcp_service_account" in st.secrets:
        sa = dict(st.secrets["gcp_service_account"])
        p_key = sa["private_key"].replace("\\n", "\n")
        sa["private_key"] = "\n".join([line.strip() for line in p_key.split("\n") if line.strip()])
        creds = ServiceAccountCredentials.from_json_keyfile_dict(sa, SCOPES)
    else:
        creds = ServiceAccountCredentials.from_json_keyfile_name(
            SERVICE_ACCOUNT_FILE, SCOPES
        )
    return gspread.authorize(creds)


def get_sheet(tab_name: str):
    client = _get_gspread_client()
    return client.open("fanza_db").worksheet(tab_name)


# ---------------------------------------------------------------------------
# DMM API ãƒ˜ãƒ«ãƒ‘ãƒ¼
# ---------------------------------------------------------------------------
API_ID = st.secrets["api_id"]
AFFILIATE_ID = st.secrets["affiliate_id"]
DMM_ITEM_ENDPOINT = "https://api.dmm.com/affiliate/v3/ItemList"
DMM_ACTRESS_ENDPOINT = "https://api.dmm.com/affiliate/v3/ActressSearch"


def search_actress_api(keyword: str, hits: int = 10):
    params = {
        "api_id": API_ID,
        "affiliate_id": AFFILIATE_ID,
        "keyword": keyword,
        "hits": hits,
        "output": "json",
    }
    resp = requests.get(DMM_ACTRESS_ENDPOINT, params=params, timeout=15)
    resp.raise_for_status()
    return resp.json().get("result", {}).get("actress", [])


@st.cache_data(ttl=600, show_spinner=False)
def search_items_by_actress(actress_id: str, hits: int = 30):
    """APIæ¤œç´¢çµæœã‚’10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€‚ãƒšãƒ¼ã‚¸ãƒªãƒ­ãƒ¼ãƒ‰ã§ã‚‚å†å–å¾—ã—ãªã„ã€‚"""
    params = {
        "api_id": API_ID,
        "affiliate_id": AFFILIATE_ID,
        "site": "FANZA",
        "service": "mono",
        "floor": "dvd",
        "article": "actress",
        "article_id": actress_id,
        "hits": hits,
        "sort": "date",
        "output": "json",
    }
    resp = requests.get(DMM_ITEM_ENDPOINT, params=params, timeout=15)
    resp.raise_for_status()
    return resp.json().get("result", {}).get("items", [])


def make_item_url(content_id: str) -> str:
    return f"https://www.dmm.co.jp/mono/dvd/-/detail/=/cid={content_id}/"


# filter_items ã¯ filters.py ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿


# ---------------------------------------------------------------------------
# NHãƒ–ãƒ­ã‚° ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ˜ãƒ«ãƒ‘ãƒ¼
# ---------------------------------------------------------------------------
NH_BLOG_BASE = "https://main.av-somurie.xyz"
NH_BLOG_SEARCH_URL = NH_BLOG_BASE + "/?s={query}&feed=rss2"
NH_BLOG_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)


def _nh_get(url: str) -> str:
    """User-Agent ä»˜ãã§ GET ã—ã€HTMLãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    resp = requests.get(url, headers={"User-Agent": NH_BLOG_UA}, timeout=60)
    resp.raise_for_status()
    return resp.text


def _fetch_rss(url: str) -> feedparser.FeedParserDict:
    """User-Agent ä»˜ãã§ RSS ã‚’å–å¾—ã— feedparser ã§ãƒ‘ãƒ¼ã‚¹ã—ã¦è¿”ã™ã€‚"""
    resp = requests.get(url, headers={"User-Agent": NH_BLOG_UA}, timeout=30)
    resp.raise_for_status()
    return feedparser.parse(resp.content)


def search_nh_blog(actress_name: str) -> dict:
    """NHãƒ–ãƒ­ã‚°ã‚’æ¤œç´¢ã—ã€å¥³å„ªã®ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ãƒ»è¨˜äº‹æ•°ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: {category_path, articles: [{title, link, published}], count}
    category_path ãŒç©ºã®å ´åˆã¯è©²å½“ãªã—ã€‚"""
    url = NH_BLOG_SEARCH_URL.format(query=urllib.parse.quote(actress_name))
    feed = _fetch_rss(url)

    # è¨˜äº‹ãƒªãƒ³ã‚¯ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’é€†ç®—
    # ä¾‹: https://main.av-somurie.xyz/tagyou/takanashi_kanon/post-57648/
    #   â†’ category_path = "tagyou/takanashi_kanon"
    category_path = ""
    articles = []
    for entry in feed.entries:
        link = entry.get("link", "")
        title = entry.get("title", "")
        published = entry.get("published", "")
        # /actress_search/ ã¯å¥³å„ªä¸€è¦§ãƒšãƒ¼ã‚¸ãªã®ã§é™¤å¤–
        if "/actress_search/" in link:
            continue
        
        # è¨˜äº‹ãƒªãƒ³ã‚¯ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’æŠ½å‡º
        # ä¾‹: https://main.av-somurie.xyz/tagyou/takanashi_kanon/post-57648/
        m = re.match(r"https?://main\.av-somurie\.xyz/([\w]+/[\w]+)/post-\d+/?", link)
        if m:
            path = m.group(1)
            # URLã®ãƒ‘ã‚¹ã«ã€æ¤œç´¢ã—ãŸå¥³å„ªåã®ãƒ­ãƒ¼ãƒå­—èª­ã¿ãªã©ãŒå…¥ã£ã¦ã„ã‚‹ã‹å®Œå…¨ãªä¸€è‡´åˆ¤å®šã¯é›£ã—ã„ãŒã€
            # tagyou/takanashi_kanon ã®ã‚ˆã†ãªãƒ‘ã‚¹ã«ãªã£ã¦ã„ã‚‹ã¯ãšã€‚
            # ä»–ã®å¥³å„ª(nanamiç­‰)ã®å˜ãªã‚‹å…±æ¼”è¨˜äº‹ã§ã‚ã‚Œã°ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ãŒç•°ãªã‚‹ã€‚
            # ã‚ˆã£ã¦æœ€åˆã®è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’ãã®å¥³å„ªã®å°‚ç”¨ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã¨è¦‹ãªã™ã€‚
            # ã‚‚ã—RSSã®ã€Œã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ã‚¿ã‚°ç­‰ã®æƒ…å ±ã§åˆ¤åˆ¥ã§ãã‚‹ãªã‚‰ãã‚ŒãŒæœ€å–„ã ãŒã€
            # ç¾çŠ¶ã¯1ç•ªç›®ã«è¦‹ã¤ã‹ã£ãŸå®Ÿéš›ã®ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’ä¿¡ã˜ã¦ã€ãã‚Œä»¥å¤–ã¯å¼¾ãã€‚
            if not category_path:
                category_path = path

            # ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ãŒæœ€åˆã«ç¢ºå®šã—ãŸã‚‚ã®ã¨ä¸€è‡´ã™ã‚‹è¨˜äº‹ã ã‘ã‚’æ¡ç”¨ï¼ˆåˆ¥å¥³å„ªã®ã‚«ãƒ†ã‚´ãƒªè¨˜äº‹ã‚’é™¤å¤–ï¼‰
            if path == category_path:
                articles.append({
                    "title": title,
                    "link": link,
                    "published": published,
                })

    # ã•ã‚‰ã«å³å¯†ã«ã€å–å¾—ã—ãŸ articles ãŒæœ¬å½“ã«ãã®å¥³å„ªå‘ã‘ã‹æ¤œè¨¼ãŒå¿…è¦ãªã‚‰è¡Œã†ãŒã€
    # åŸºæœ¬çš„ã«åå‰æ¤œç´¢ã§ãƒˆãƒƒãƒ—ã«å‡ºã¦ãã‚‹ä¸€ç•ªå¤šã„ã‚«ãƒ†ã‚´ãƒªã‚’æ¡ç”¨ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã«ã™ã‚‹
    if articles:
        # ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã®æŠ½å‡ºã¨ã‚«ã‚¦ãƒ³ãƒˆ
        path_counts = {}
        for entry in feed.entries:
            link = entry.get("link", "")
            if "/actress_search/" in link: continue
            m = re.match(r"https?://main\.av-somurie\.xyz/([\w]+/[\w]+)/post-\d+/?", link)
            if m:
                p = m.group(1)
                path_counts[p] = path_counts.get(p, 0) + 1
                
        # ä¸€ç•ªå‡ºç¾é »åº¦ãŒé«˜ã„ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’æ­£è§£ã¨ã™ã‚‹
        if path_counts:
            best_path = max(path_counts, key=path_counts.get)
            category_path = best_path
            
            # best_path ã®è¨˜äº‹ã ã‘å†åé›†
            articles = []
            for entry in feed.entries:
                link = entry.get("link", "")
                title = entry.get("title", "")
                published = entry.get("published", "")
                m = re.match(r"https?://main\.av-somurie\.xyz/([\w]+/[\w]+)/post-\d+/?", link)
                if m and m.group(1) == best_path:
                    articles.append({
                        "title": title,
                        "link": link,
                        "published": published,
                    })

    return {
        "category_path": category_path,
        "articles": articles,
        "count": len(articles),
    }


def _scrape_nh_face_img(category_path: str) -> str:
    """ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸HTMLã‹ã‚‰é¡”ç”»åƒURLã®ã¿ã‚’å–å¾—ã™ã‚‹ã€‚"""
    cat_url = f"{NH_BLOG_BASE}/category/{category_path}/"
    html = _nh_get(cat_url)
    profile_m = re.search(
        r'<article[^>]*class=["\'][^"\']*category-content[^"\']*["\'][^>]*>(.*?)</article>',
        html, re.DOTALL,
    )
    if profile_m:
        img_m = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', profile_m.group(1))
        if img_m:
            return img_m.group(1)
    return ""


def _fetch_nh_category_rss(category_path: str, max_items: int = 5) -> list[dict]:
    """ã‚«ãƒ†ã‚´ãƒª RSS ã‹ã‚‰æœ€æ–°ä½œå“ã‚’å–å¾—ã™ã‚‹ï¼ˆè»½é‡ãƒ»é«˜é€Ÿï¼‰ã€‚
    æˆ»ã‚Šå€¤: [{title, link, thumbnail, published}]"""
    rss_url = f"{NH_BLOG_BASE}/category/{category_path}/?feed=rss2"
    feed = _fetch_rss(rss_url)
    works = []
    for entry in feed.entries[:max_items]:
        title = entry.get("title", "")
        link = entry.get("link", "")
        
        # æŠ•ç¨¿æ—¥æ™‚ã‚’ FANZA ã¨åŒã˜ YYYY-MM-DD HH:MM:SS å½¢å¼ã«æƒãˆã‚‹
        published_parsed = entry.get("published_parsed")
        if published_parsed:
            published = time.strftime('%Y-%m-%d %H:%M:%S', published_parsed)
        else:
            published = entry.get("published", "")

        # content:encoded ã‚„ summary ã‹ã‚‰ç”»åƒã‚’æŠ½å‡º
        content = ""
        if "content" in entry and entry.content:
            content = entry.content[0].get("value", "")
        if not content:
            content = entry.get("summary", "")
            
        imgs = re.findall(r'<img[^>]+src=["\']([^"\']+)["\']', content)
        
        thumb = ""
        # 1. pl.(jpg|webp|png) ã‚„ top.jpg (ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç”»åƒ) ã‚’å„ªå…ˆçš„ã«æ¢ã™
        for img in imgs:
            if re.search(r'(?:pl|top)\.(?:jpg|jpeg|png|webp)', img, re.IGNORECASE):
                thumb = img
                break
                
        # 2. ãªã‘ã‚Œã°ã€ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ (jp-X.jpg, -X.jpg, _X.jpg) ãŠã‚ˆã³ ãƒãƒŠãƒ¼ç”»åƒ ä»¥å¤–ã‚’æ¢ã™
        if not thumb:
            for img in imgs:
                if not re.search(r'(?:jp-\d+|-\d+|_\d+)\.(?:jpg|jpeg|png|webp)|bannar', img, re.IGNORECASE):
                    thumb = img
                    break
                    
        # 3. ãã‚Œã§ã‚‚ãªã‘ã‚Œã°æœ€åˆã®ç”»åƒ
        if not thumb and imgs:
            thumb = imgs[0]

        if title:
            works.append({
                "title": title,
                "link": link,
                "thumbnail": thumb,
                "published": published,
            })
    return works


@st.cache_data(ttl=3600, show_spinner=False)
def fetch_nh_blog_items(category_path: str, max_items: int = 5) -> list[dict]:
    """NHãƒ–ãƒ­ã‚° ã‚«ãƒ†ã‚´ãƒªRSS ã‹ã‚‰æœ€æ–°ä½œå“ã‚’å–å¾—ï¼ˆ1 æ™‚é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰ã€‚
    æˆ»ã‚Šå€¤: [{title, link, thumbnail, published}]
    ä¾‹å¤–æ™‚ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã›ãšæ¬¡å›ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ã€‚"""
    return _fetch_nh_category_rss(category_path, max_items)


# ---------------------------------------------------------------------------
# ã‚¹ãƒ—ã‚·æ“ä½œãƒ˜ãƒ«ãƒ‘ãƒ¼
# ---------------------------------------------------------------------------
def get_all_actresses(force_refresh: bool = False) -> pd.DataFrame:
    if not force_refresh and "df_actresses_cache" in st.session_state:
        return st.session_state.df_actresses_cache
    ws = get_sheet("actresses")
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã« source åˆ—ãŒãªã‘ã‚Œã°è‡ªå‹•è¿½åŠ 
    header = ws.row_values(1)
    if "source" not in header:
        ws.update_cell(1, len(header) + 1, "source")
    records = ws.get_all_records()
    if not records:
        df = pd.DataFrame(columns=["name", "actress_id", "image_url", "group", "source"])
    else:
        df = pd.DataFrame(records)
        if "group" not in df.columns:
            df["group"] = ""
        df["group"] = df["group"].fillna("").astype(str)
        # source åˆ—ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºæ¬„ã¯ FANZA ã¨ã—ã¦æ‰±ã†
        if "source" not in df.columns:
            df["source"] = "FANZA"
        df["source"] = df["source"].fillna("").astype(str)
        df["source"] = df["source"].replace("", "FANZA")
    st.session_state.df_actresses_cache = df
    return df


def _invalidate_actress_cache():
    st.session_state.pop("df_actresses_cache", None)
    _get_gspread_client.clear()


def add_actresses_batch(actress_list: list[tuple[str, str, str, str]]):
    """actress_list: [(name, actress_id, image_url, source), ...]"""
    ws = get_sheet("actresses")
    rows = [[name, str(aid), img, "", source] for name, aid, img, source in actress_list]
    ws.append_rows(rows)
    _invalidate_actress_cache()


def delete_actress(actress_id: str):
    ws = get_sheet("actresses")
    records = ws.get_all_records()
    for i, r in enumerate(records, start=2):
        if str(r.get("actress_id")) == str(actress_id):
            ws.delete_rows(i)
            break
    _invalidate_actress_cache()


def _rebuild_sheet(df: pd.DataFrame):
    ws = get_sheet("actresses")
    ws.clear()
    ws.append_row(["name", "actress_id", "image_url", "group", "source"])
    if not df.empty:
        cols = ["name", "actress_id", "image_url", "group", "source"]
        for c in cols:
            if c not in df.columns:
                df[c] = "FANZA" if c == "source" else ""
        rows = df[cols].values.tolist()
        ws.append_rows(rows)
    _invalidate_actress_cache()


def save_actress_order(ordered_groups: list[dict]):
    ws = get_sheet("actresses")
    records = ws.get_all_records()
    id_map = {}
    for r in records:
        id_map[str(r.get("actress_id", ""))] = r

    new_rows = []
    for container in ordered_groups:
        group_name = container["header"]
        actual_group = group_name if group_name != "æœªåˆ†é¡" else ""
        for label in container["items"]:
            aid = label.rsplit("[", 1)[-1].rstrip("]").strip()
            if aid in id_map:
                r = id_map[aid]
                src = str(r.get("source", "")) or "FANZA"
                new_rows.append([
                    r.get("name", ""),
                    str(r.get("actress_id", "")),
                    r.get("image_url", ""),
                    actual_group,
                    src,
                ])

    ws.clear()
    ws.append_row(["name", "actress_id", "image_url", "group", "source"])
    if new_rows:
        ws.append_rows(new_rows)
    _invalidate_actress_cache()


def swap_actress_order(df: pd.DataFrame, idx_a: int, idx_b: int):
    rows = df.values.tolist()
    rows[idx_a], rows[idx_b] = rows[idx_b], rows[idx_a]
    new_df = pd.DataFrame(rows, columns=df.columns)
    _rebuild_sheet(new_df)


# ---------------------------------------------------------------------------
# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
# ---------------------------------------------------------------------------
def _cb_batch_add():
    """æ¤œç´¢çµæœã‹ã‚‰å…¨å¥³å„ªã‚’ä¸€æ‹¬ç™»éŒ²ã™ã‚‹ã€‚"""
    all_results = st.session_state.search_results
    collected = []
    for name, results in all_results.items():
        if len(results) == 1:
            act = results[0]
            aid = str(act.get("id", ""))
            img = (
                act.get("imageURL", {}).get("small", "")
                or act.get("imageURL", {}).get("large", "")
            )
            collected.append((act.get("name", name), aid, img, "FANZA"))
        else:
            for act in results:
                aid = str(act.get("id", ""))
                if st.session_state.get(f"chk_{aid}", False):
                    img = (
                        act.get("imageURL", {}).get("small", "")
                        or act.get("imageURL", {}).get("large", "")
                    )
                    collected.append((act.get("name", name), aid, img, "FANZA"))
    if collected:
        try:
            add_actresses_batch(collected)
            names = ", ".join(c[0] for c in collected)
            st.session_state.add_success = names
            st.session_state.search_results = {}
            st.session_state.pending_names = ""
        except Exception as e:
            st.session_state.search_error = f"è¿½åŠ å¤±æ•—: {e}"


def _cb_swap(df, idx_a, idx_b):
    swap_actress_order(df, idx_a, idx_b)
    search_items_by_actress.clear()


# ---------------------------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ---------------------------------------------------------------------------
def parse_names(text: str) -> list[str]:
    """ã‚«ãƒ³ãƒãƒ»æ”¹è¡Œãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ãªã©ã§åŒºåˆ‡ã£ã¦åå‰ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    names = re.split(r"[,ã€\n\r\tã€€]+", text.strip())
    return [n.strip() for n in names if n.strip()]


def render_actress_header(name: str, image_url: str):
    missav = "https://missav.ai/ja/search/" + urllib.parse.quote(name)
    img = f'<img src="{image_url}" alt="">' if image_url else ""
    st.markdown(
        f'<div class="actress-hdr">'
        f"  {img}"
        f'  <span class="name">{name}</span>'
        f'  <a class="missav" href="{missav}" target="_blank">[MissAV]</a>'
        f"</div>",
        unsafe_allow_html=True,
    )


def render_hscroll(items: list[dict]):
    if not items:
        st.caption("æ–°ä½œãªã—")
        return

    cards = []
    for item in items:
        title = item.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
        date = item.get("date", "")[:10]
        cid = item.get("content_id", "")
        url = make_item_url(cid) if cid else "#"
        img = (
            item.get("imageURL", {}).get("large", "")
            or item.get("imageURL", {}).get("small", "")
        )
        img_tag = f'<img src="{img}" loading="lazy">' if img else ""
        cards.append(
            f'<a class="icard" href="{url}" target="_blank">'
            f"  {img_tag}"
            f'  <div class="ttl">{title}</div>'
            f'  <div class="dt">ğŸ“… {date}</div>'
            f"</a>"
        )

    st.markdown(
        '<div class="hscroll">' + "".join(cards) + "</div>",
        unsafe_allow_html=True,
    )


def render_hscroll_blog(items: list[dict]):
    """NHãƒ–ãƒ­ã‚°ä½œå“ã‚’ã‚«ãƒ¼ãƒ‰å‹ã§æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºã™ã‚‹ã€‚"""
    if not items:
        st.caption("ä½œå“ãªã—")
        return

    cards = []
    for item in items:
        title = item.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
        url = item.get("link", "#")
        thumb = item.get("thumbnail", "")
        date = item.get("published", "")[:10]
        img_tag = f'<img src="{thumb}" loading="lazy">' if thumb else ""
        cards.append(
            f'<a class="icard" href="{url}" target="_blank">'
            f"  {img_tag}"
            f'  <div class="ttl">{title}</div>'
            f'  <div class="dt">ğŸ“… {date}</div>'
            f"</a>"
        )

    st.markdown(
        '<div class="hscroll">' + "".join(cards) + "</div>",
        unsafe_allow_html=True,
    )


# ---------------------------------------------------------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼: å¥³å„ªä¸€æ‹¬æ¤œç´¢ & è¿½åŠ 
# ---------------------------------------------------------------------------
with st.sidebar:
    st.markdown("### ğŸ” å¥³å„ªè¿½åŠ ")
    st.caption("åå‰ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›ã—ã€Œæ¤œç´¢ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    if st.session_state.add_success:
        st.success(f"{st.session_state.add_success} ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
        st.session_state.add_success = ""

    if st.session_state.search_error:
        st.error(st.session_state.search_error)
        st.session_state.search_error = ""

    # æƒ…å ±å…ƒãƒˆã‚°ãƒ«
    search_source = st.radio(
        "æƒ…å ±å…ƒ",
        ["FANZAå…¬å¼", "NH"],
        horizontal=True,
        key="search_source_radio",
    )

    with st.form("multi_search_form", clear_on_submit=True):
        query = st.text_area(
            "å¥³å„ªåï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
            placeholder="æ·±ç”°ãˆã„ã¿, ä¸‰ä¸Šæ‚ äºœ, æ©‹æœ¬ã‚ã‚Šãª",
            height=80,
        )
        submitted = st.form_submit_button("æ¤œç´¢", use_container_width=True)

    if submitted and query:
        names = parse_names(query)
        if search_source == "FANZAå…¬å¼":
            # --- FANZA æ¤œç´¢ (æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯) ---
            old_results = dict(st.session_state.search_results)
            errors = []
            for name in names:
                if name in old_results:
                    continue
                try:
                    found = search_actress_api(name, hits=5)
                    if found:
                        old_results[name] = found
                    else:
                        errors.append(f"ã€Œ{name}ã€: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    errors.append(f"ã€Œ{name}ã€: {e}")
            st.session_state.search_results = old_results
            if errors:
                st.session_state.search_error = " / ".join(errors)
        else:
            # --- NHæ¤œç´¢ (ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼â†’é¸æŠæ–¹å¼) ---
            old_nh = dict(st.session_state.nh_search_results)
            errors = []
            for name in names:
                if name in old_nh:
                    continue
                try:
                    result = search_nh_blog(name)
                    cat_path = result.get("category_path", "")
                    articles = result.get("articles", [])
                    if cat_path and articles:
                        # ã‚«ãƒ†ã‚´ãƒªãƒšãƒ¼ã‚¸ã‹ã‚‰é¡”ç”»åƒã‚’å–å¾—
                        try:
                            face_img = _scrape_nh_face_img(cat_path)
                        except Exception:
                            face_img = ""
                        old_nh[name] = {
                            "category_path": cat_path,
                            "articles": articles,
                            "face_img": face_img,
                            "count": len(articles),
                        }
                    else:
                        errors.append(f"ã€Œ{name}ã€: è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    errors.append(f"ã€Œ{name}ã€: {e}")
            st.session_state.nh_search_results = old_nh
            if errors:
                st.session_state.search_error = " / ".join(errors)
        st.rerun()

    # --- è“„ç©ã•ã‚ŒãŸçµæœè¡¨ç¤º (FANZAæ¤œç´¢çµæœ) ---
    if st.session_state.search_results:
        all_results = st.session_state.search_results
        st.markdown(f"**ğŸ” FANZAæ¤œç´¢çµæœ: {len(all_results)}å**")

        st.button(
            "âœ… ã¾ã¨ã‚ã¦ç™»éŒ²",
            use_container_width=True, type="primary",
            on_click=_cb_batch_add, key="batch_add_btn",
        )

        if st.button("ğŸ—‘ï¸ æ¤œç´¢çµæœã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.search_results = {}
            st.rerun()

        for search_name, results in all_results.items():
            st.markdown(f"**{search_name}**")
            if len(results) == 1:
                act = results[0]
                aname = act.get("name", "ä¸æ˜")
                aid = str(act.get("id", ""))
                img = (
                    act.get("imageURL", {}).get("small", "")
                    or act.get("imageURL", {}).get("large", "")
                )
                r1, r2 = st.columns([1, 3])
                with r1:
                    if img:
                        st.image(img, width=45)
                with r2:
                    st.markdown(
                        f"<span style='color:#f0f0f0'>{aname}</span> "
                        f"<span style='color:#ff4d8d;font-size:0.75rem'>"
                        f"ID:{aid}</span> âœ…",
                        unsafe_allow_html=True,
                    )
            else:
                for act in results:
                    aid = str(act.get("id", ""))
                    aname = act.get("name", "ä¸æ˜")
                    img = (
                        act.get("imageURL", {}).get("small", "")
                        or act.get("imageURL", {}).get("large", "")
                    )
                    chk_c, img_c, info_c = st.columns([0.5, 1, 3])
                    with chk_c:
                        st.checkbox(
                            " ", key=f"chk_{aid}",
                            label_visibility="collapsed",
                        )
                    with img_c:
                        if img:
                            st.image(img, width=40)
                    with info_c:
                        st.markdown(
                            f"<span style='color:#f0f0f0'>{aname}</span> "
                            f"<span style='color:#ff4d8d;font-size:0.7rem'>"
                            f"ID:{aid}</span>",
                            unsafe_allow_html=True,
                        )
            st.markdown("---")

    # --- è“„ç©ã•ã‚ŒãŸçµæœè¡¨ç¤º (NHæ¤œç´¢çµæœ) ---
    if st.session_state.nh_search_results:
        nh_results = st.session_state.nh_search_results
        st.markdown(f"**ğŸ” NHæ¤œç´¢çµæœ: {len(nh_results)}å**")

        def _cb_nh_batch_add():
            """NHæ¤œç´¢çµæœã‹ã‚‰å…¨å¥³å„ªã‚’ä¸€æ‹¬ç™»éŒ²ã™ã‚‹ã€‚"""
            collected = []
            for name, data in st.session_state.nh_search_results.items():
                # actress_id ã«ã‚«ãƒ†ã‚´ãƒªãƒ‘ã‚¹ã‚’ä¿å­˜ (ä¾‹: tagyou/takanashi_kanon)
                aid = data.get("category_path", f"nhb-{uuid.uuid4().hex[:12]}")
                face_img = data.get("face_img", "")
                collected.append((name, aid, face_img, "NH_BLOG"))
            if collected:
                try:
                    add_actresses_batch(collected)
                    names_str = ", ".join(c[0] for c in collected)
                    st.session_state.add_success = names_str
                    st.session_state.nh_search_results = {}
                except Exception as e:
                    st.session_state.search_error = f"è¿½åŠ å¤±æ•—: {e}"

        st.button(
            "âœ… ã¾ã¨ã‚ã¦ç™»éŒ²",
            use_container_width=True, type="primary",
            on_click=_cb_nh_batch_add, key="nh_batch_add_btn",
        )

        if st.button("ğŸ—‘ï¸ NHæ¤œç´¢çµæœã‚’ã‚¯ãƒªã‚¢", use_container_width=True,
                     key="nh_clear_btn"):
            st.session_state.nh_search_results = {}
            st.rerun()

        for search_name, data in nh_results.items():
            face_img = data.get("face_img", "")
            count = data.get("count", 0)
            r1, r2 = st.columns([1, 3])
            with r1:
                if face_img:
                    st.image(face_img, width=45)
            with r2:
                st.markdown(
                    f"<span style='color:#f0f0f0;font-weight:600'>"
                    f"{search_name}</span> "
                    f"<span style='color:#ff4d8d;font-size:0.75rem'>"
                    f"({count}ä»¶ã®è¨˜äº‹)</span> âœ…",
                    unsafe_allow_html=True,
                )
            st.markdown("---")

# ---------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼: ã‚¿ã‚¤ãƒˆãƒ« + ç·¨é›†ãƒœã‚¿ãƒ³
# ---------------------------------------------------------------------------
df_actresses = get_all_actresses()

hdr_left, hdr_right = st.columns([6, 1])
with hdr_left:
    st.markdown(
        '<h1 style="margin:0;padding:0;color:#f0f0f0;">AV Monitor</h1>',
        unsafe_allow_html=True,
    )
with hdr_right:
    if not df_actresses.empty:
        if st.button(
            "âœï¸ ç·¨é›†" if not st.session_state.edit_mode else "âœ… å®Œäº†",
            use_container_width=True,
        ):
            st.session_state.edit_mode = not st.session_state.edit_mode
            st.rerun()

st.markdown("---")

# ---------------------------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
# ---------------------------------------------------------------------------
if df_actresses.empty:
    st.info("å·¦ä¸Šã® âŒƒ ã‹ã‚‰ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‹ãã€å¥³å„ªã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
else:
    # ã‚°ãƒ«ãƒ¼ãƒ—åˆ†é¡
    groups: dict[str, list] = {}
    group_order: list[str] = []
    for idx, row in df_actresses.iterrows():
        g = row["group"] if row["group"] else "æœªåˆ†é¡"
        if g not in groups:
            groups[g] = []
            group_order.append(g)
        groups[g].append({"row": row, "df_idx": idx})

    for eg in st.session_state.get("extra_groups", []):
        if eg not in groups:
            groups[eg] = []
            group_order.append(eg)

    # ========== ç·¨é›†ãƒ¢ãƒ¼ãƒ‰ ==========
    if st.session_state.edit_mode:
        st.subheader("ğŸ“ ç·¨é›†")

        # --- 1) ã‚°ãƒ«ãƒ¼ãƒ—é †åºã®å…¥ã‚Œæ›¿ãˆ ---
        st.markdown("#### ğŸ”€ ã‚°ãƒ«ãƒ¼ãƒ—é †åº")
        st.caption("â¬†â¬‡ ã§ã‚°ãƒ«ãƒ¼ãƒ—ã®è¡¨ç¤ºé †ã‚’å¤‰æ›´ã€‚å¤‰æ›´å¾Œã€ŒğŸ’¾ ã‚°ãƒ«ãƒ¼ãƒ—é †ã‚’ä¿å­˜ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ã‚°ãƒ«ãƒ¼ãƒ—é †åºã‚’ä¿æŒ
        if "edit_group_order" not in st.session_state:
            st.session_state.edit_group_order = list(group_order)

        ego = st.session_state.edit_group_order

        def _swap_groups(idx_a, idx_b):
            eo = st.session_state.edit_group_order
            eo[idx_a], eo[idx_b] = eo[idx_b], eo[idx_a]

        for gi, gname in enumerate(ego):
            gc1, gc2, gc3 = st.columns([6, 1, 1])
            with gc1:
                cnt = len(groups.get(gname, []))
                st.markdown(
                    f'<span style="color:#f0f0f0;font-weight:600">{gname}</span>'
                    f' <span style="color:#888;font-size:0.8rem">({cnt}äºº)</span>',
                    unsafe_allow_html=True,
                )
            with gc2:
                st.button(
                    "â¬†", key=f"gup_{gi}",
                    disabled=(gi == 0),
                    on_click=_swap_groups,
                    args=(gi, gi - 1 if gi > 0 else gi),
                    use_container_width=True,
                )
            with gc3:
                st.button(
                    "â¬‡", key=f"gdn_{gi}",
                    disabled=(gi == len(ego) - 1),
                    on_click=_swap_groups,
                    args=(gi, gi + 1 if gi < len(ego) - 1 else gi),
                    use_container_width=True,
                )

        if st.button("ğŸ’¾ ã‚°ãƒ«ãƒ¼ãƒ—é †ã‚’ä¿å­˜", use_container_width=True, type="primary"):
            # ã‚°ãƒ«ãƒ¼ãƒ—é †åºã‚’åæ˜ ã•ã›ã¦å…¨ãƒ‡ãƒ¼ã‚¿æ›¸ãç›´ã—
            new_order = st.session_state.edit_group_order
            ws = get_sheet("actresses")
            records = ws.get_all_records()
            id_map = {}
            for r in records:
                id_map[str(r.get("actress_id", ""))] = r

            new_rows = []
            for gname in new_order:
                actual_g = gname if gname != "æœªåˆ†é¡" else ""
                for m in groups.get(gname, []):
                    aid = str(m["row"]["actress_id"])
                    if aid in id_map:
                        ir = id_map[aid]
                        src = str(ir.get("source", "")) or "FANZA"
                        new_rows.append([
                            ir.get("name", ""),
                            str(ir.get("actress_id", "")),
                            ir.get("image_url", ""),
                            actual_g,
                            src,
                        ])

            ws.clear()
            ws.append_row(["name", "actress_id", "image_url", "group", "source"])
            if new_rows:
                ws.append_rows(new_rows)
            _invalidate_actress_cache()
            st.session_state.pop("edit_group_order", None)
            st.success("ã‚°ãƒ«ãƒ¼ãƒ—é †ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            st.rerun()

        st.markdown("---")

        # --- 2) å¥³å„ªã®ç§»å‹• (ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—) ---
        st.markdown("#### ğŸ–ï¸ å¥³å„ªã®ç§»å‹•")
        st.caption(
            "å¥³å„ªã‚’ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ãƒ‰ãƒ©ãƒƒã‚°ã—ã¦ç§»å‹•ã€‚"
            "å¤‰æ›´å¾Œã€ŒğŸ’¾ ä¿å­˜ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
        )

        sortable_data = [
            {
                "header": g,
                "items": [
                    f'{m["row"]["name"]} [{m["row"]["actress_id"]}]'
                    for m in groups[g]
                ],
            }
            for g in group_order
        ]

        custom_css = """
        .sortable-component { border-radius: 10px; }
        .sortable-container {
            background: #141414; border-radius: 8px; margin-bottom: 8px;
            border: 1px solid #222;
        }
        .sortable-container-header {
            background: linear-gradient(90deg, #1a1a1a, #222);
            color: #f0f0f0;
            padding: 8px 12px; border-radius: 8px 8px 0 0; font-weight: 600;
        }
        .sortable-container-body { background: #141414; padding: 4px; }
        .sortable-item {
            background: #1e1e1e; color: #f0f0f0;
            border: 1px solid #333;
            border-radius: 6px; padding: 6px 10px; margin: 3px 0;
            font-size: 0.85rem; cursor: grab;
            transition: all 0.15s ease;
        }
        .sortable-item:hover {
            background: #2a2a2a;
            border-color: #ff4d8d;
        }
        """

        sorted_result = sort_items(
            sortable_data,
            multi_containers=True,
            direction="vertical",
            custom_style=custom_css,
        )

        if st.button("ğŸ’¾ ä¸¦ã³é †ã‚’ä¿å­˜", use_container_width=True, type="primary"):
            with st.spinner("ä¿å­˜ä¸­â€¦"):
                save_actress_order(sorted_result)
                st.session_state.pop("extra_groups", None)
                st.session_state.pop("edit_group_order", None)
            st.success("ä¸¦ã³é †ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            st.rerun()

        st.markdown("---")

        # --- 3) ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ (æŠ˜ã‚ŠãŸãŸã¿) ---
        with st.expander("â• ã‚°ãƒ«ãƒ¼ãƒ—ä½œæˆ", expanded=False):
            with st.form("new_group_form"):
                new_group_name = st.text_input(
                    "æ–°ã—ã„ã‚°ãƒ«ãƒ¼ãƒ—å", placeholder="ä¾‹: ãŠæ°—ã«å…¥ã‚Š",
                    label_visibility="collapsed",
                )
                create_submitted = st.form_submit_button(
                    "ä½œæˆ", use_container_width=True
                )
            if create_submitted and new_group_name:
                if new_group_name in groups:
                    st.warning(f"ã€Œ{new_group_name}ã€ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚")
                else:
                    if "extra_groups" not in st.session_state:
                        st.session_state.extra_groups = []
                    st.session_state.extra_groups.append(new_group_name)
                    st.rerun()

        # --- 4) ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤ (æŠ˜ã‚ŠãŸãŸã¿) ---
        with st.expander("ğŸ—‘ï¸ ã‚°ãƒ«ãƒ¼ãƒ—å‰Šé™¤", expanded=False):
            deletable = [g for g in group_order if g != "æœªåˆ†é¡"]
            if deletable:
                del_group = st.selectbox(
                    "å‰Šé™¤ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—", deletable,
                    label_visibility="collapsed",
                )
                if st.button(
                    f"ã€Œ{del_group}ã€ã‚’å‰Šé™¤",
                    use_container_width=True,
                ):
                    extras = st.session_state.get("extra_groups", [])
                    if del_group in extras:
                        extras.remove(del_group)
                    else:
                        with st.spinner("å‰Šé™¤ä¸­â€¦"):
                            ws = get_sheet("actresses")
                            records = ws.get_all_records()
                            for i, r in enumerate(records, start=2):
                                if str(r.get("group", "")) == del_group:
                                    ws.update_cell(i, 4, "")
                            _invalidate_actress_cache()
                    st.success(
                        f"ã€Œ{del_group}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"
                    )
                    st.rerun()
            else:
                st.caption("å‰Šé™¤å¯èƒ½ãªã‚°ãƒ«ãƒ¼ãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        # --- 5) å¥³å„ªå‰Šé™¤ (æŠ˜ã‚ŠãŸãŸã¿ + æ¤œç´¢) ---
        with st.expander("ğŸ—‘ï¸ å¥³å„ªå‰Šé™¤", expanded=False):
            del_filter = st.text_input(
                "åå‰ã§æ¤œç´¢", placeholder="åå‰ã‚’å…¥åŠ›ã—ã¦çµã‚Šè¾¼ã¿",
                key="del_actress_filter", label_visibility="collapsed",
            )
            filtered_rows = [
                row for _, row in df_actresses.iterrows()
                if not del_filter or del_filter in row["name"]
            ]
            if filtered_rows:
                for row_i, row in enumerate(filtered_rows):
                    if row_i > 0:
                        st.markdown(
                            '<hr style="margin:4px 0;border:none;'
                            'border-top:1px solid #333;">',
                            unsafe_allow_html=True,
                        )
                    c1, c2 = st.columns([6, 1])
                    with c1:
                        st.markdown(
                            f'<span style="color:#f0f0f0;font-size:0.9rem">'
                            f'{row["name"]}</span>',
                            unsafe_allow_html=True,
                        )
                    with c2:
                        if st.button("âœ•", key=f"del_{row_i}_{row['actress_id']}",
                                     use_container_width=True):
                            delete_actress(str(row["actress_id"]))
                            st.success(f"{row['name']} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                            st.rerun()
            else:
                st.caption("è©²å½“ã™ã‚‹å¥³å„ªãŒã„ã¾ã›ã‚“ã€‚")

    # ========== é€šå¸¸è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ ==========
    else:
        st.session_state.pop("extra_groups", None)

        # --- å…¨å¥³å„ªã®ãƒ‡ãƒ¼ã‚¿ã‚’1å›ã§å–å¾—ï¼†ãƒ•ã‚£ãƒ«ã‚¿ (é«˜é€ŸåŒ–) ---
        filtered_cache: dict[str, list[dict]] = {}      # FANZA ç”¨
        blog_cache: dict[str, list[dict]] = {}            # NHãƒ–ãƒ­ã‚°ç”¨
        for g in group_order:
            for member in groups[g]:
                actress_id = str(member["row"]["actress_id"]).replace(".0", "").strip()
                source = str(member["row"].get("source", "")) or "FANZA"
                if source == "NH_BLOG":
                    if actress_id not in blog_cache:
                        try:
                            blog_cache[actress_id] = fetch_nh_blog_items(actress_id)
                        except Exception:
                            blog_cache[actress_id] = []
                else:
                    if actress_id not in filtered_cache:
                        try:
                            raw = search_items_by_actress(actress_id, hits=30)
                            filtered_cache[actress_id] = filter_items(
                                raw, require_sample_video=True,
                            )
                        except Exception:
                            filtered_cache[actress_id] = []
                            
        # --- ğŸ”¥ æ–°ç€ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— (å…¨å¥³å„ªã‹ã‚‰æœ€æ–°10æœ¬) ---
        all_latest: list[dict] = []
        nh_latest: list[dict] = []
        for g in group_order:
            for member in groups[g]:
                actress = member["row"]
                actress_id = str(actress["actress_id"]).replace(".0", "").strip()
                source = str(actress.get("source", "")) or "FANZA"
                if source == "NH_BLOG":
                    for it in blog_cache.get(actress_id, []):
                        entry = {
                            "title": it.get("title", ""),
                            "date": it.get("published", ""),
                            "content_id": "",
                            "_link": it.get("link", ""),
                            "_thumbnail": it.get("thumbnail", ""),
                            "_actress_name": actress["name"],
                            "_source": "NH_BLOG",
                        }
                        nh_latest.append(entry)
                else:
                    for it in filtered_cache.get(actress_id, []):
                        entry = {**it, "_actress_name": actress["name"], "_source": "FANZA"}
                        all_latest.append(entry)

        # FANZA ã®æ–°ç€ã‚½ãƒ¼ãƒˆã¨é‡è¤‡é™¤å»
        all_latest.sort(key=lambda x: x.get("date", ""), reverse=True)
        seen_keys: set[str] = set()
        unique_latest: list[dict] = []
        for it in all_latest:
            key = it.get("content_id", "")
            if key and key not in seen_keys:
                seen_keys.add(key)
                unique_latest.append(it)
            if len(unique_latest) >= 10:
                break
                
        # NH ã®æ–°ç€ã‚½ãƒ¼ãƒˆã¨é‡è¤‡é™¤å» (æŠ•ç¨¿æ—¥ãƒ™ãƒ¼ã‚¹)
        nh_latest.sort(key=lambda x: x.get("date", ""), reverse=True)
        seen_nh_keys: set[str] = set()
        unique_nh_latest: list[dict] = []
        for it in nh_latest:
            key = it.get("_link", "")
            if key and key not in seen_nh_keys:
                seen_nh_keys.add(key)
                unique_nh_latest.append(it)
            if len(unique_nh_latest) >= 10:
                break

        if unique_latest:
            st.markdown(
                '<h3 style="color:#f0f0f0;margin-bottom:4px;">'
                'ğŸ”¥ æ–°ç€ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— (FANZA)</h3>',
                unsafe_allow_html=True,
            )
            st.caption("ç™»éŒ²å¥³å„ªã®æœ€æ–°ä½œå“")
            cards = []
            for item in unique_latest:
                title = item.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
                aname = item.get("_actress_name", "")
                date = item.get("date", "")[:10]
                cid = item.get("content_id", "")
                url = make_item_url(cid) if cid else "#"
                img = (
                    item.get("imageURL", {}).get("large", "")
                    or item.get("imageURL", {}).get("small", "")
                )
                img_tag = f'<img src="{img}" loading="lazy">' if img else ""
                cards.append(
                    f'<a class="icard" href="{url}" target="_blank">'
                    f"  {img_tag}"
                    f'  <div class="ttl">{title}</div>'
                    f'  <div class="dt">ğŸ“… {date}ã€€ğŸ‘¤ {aname}</div>'
                    f"</a>"
                )
            st.markdown(
                '<div class="hscroll">' + "".join(cards) + "</div>",
                unsafe_allow_html=True,
            )
            st.markdown("---")
            
        # --- ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸€è¦§ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†åˆ©ç”¨) ---
        for g in group_order:
            # NHã‚°ãƒ«ãƒ¼ãƒ—ãªã‚‰ã°ã€ãã®ç›´å‰ã«NHå‘ã‘æ–°ç€ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é…ç½®ã™ã‚‹
            if g == "NH" and unique_nh_latest:
                st.markdown(
                    '<h3 style="color:#f0f0f0;margin-bottom:4px;">'
                    'ğŸ”¥ æ–°ç€ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ— (NH)</h3>',
                    unsafe_allow_html=True,
                )
                st.caption("NHãƒ–ãƒ­ã‚°ã®æœ€æ–°è¨˜äº‹")
                cards = []
                for item in unique_nh_latest:
                    title = item.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
                    aname = item.get("_actress_name", "")
                    date = item.get("date", "")[:10]
                    url = item.get("_link", "#")
                    img = item.get("_thumbnail", "")
                    img_tag = f'<img src="{img}" loading="lazy">' if img else ""
                    cards.append(
                        f'<a class="icard" href="{url}" target="_blank">'
                        f"  {img_tag}"
                        f'  <div class="ttl">{title}</div>'
                        f'  <div class="dt">ğŸ“… {date}ã€€ğŸ‘¤ {aname}</div>'
                        f"</a>"
                    )
                st.markdown(
                    '<div class="hscroll">' + "".join(cards) + "</div>",
                    unsafe_allow_html=True,
                )
                st.markdown("---")

            members = groups[g]
            with st.expander(f"ğŸ“‚ {g}ï¼ˆ{len(members)}äººï¼‰", expanded=False):
                for i, member in enumerate(members):
                    actress = member["row"]
                    name = actress["name"]
                    actress_id = str(actress["actress_id"]).replace(".0", "").strip()
                    face_url = str(actress.get("image_url", ""))
                    source = str(actress.get("source", "")) or "FANZA"

                    if source == "NH_BLOG":
                        render_actress_header(name, face_url)
                        items = blog_cache.get(actress_id, [])
                        render_hscroll_blog(items)
                    else:
                        render_actress_header(name, face_url)
                        items = filtered_cache.get(actress_id, [])
                        render_hscroll(items)
                    st.markdown("---")


